{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17682f87",
   "metadata": {
    "id": "17682f87"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5970bd3",
   "metadata": {
    "id": "a5970bd3"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('sentimentdataset.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b823d61a",
   "metadata": {
    "id": "b823d61a"
   },
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07dbfc0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "07dbfc0b",
    "outputId": "4d05e179-6d7c-42e4-c8b0-5c7c2b3caac9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 12:30:00</td>\n",
       "      <td>User123</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Nature #Park</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Traffic was terrible this morning.           ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2023-01-15 08:45:00</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Traffic #Morning</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Just finished an amazing workout! ðª       ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 15:45:00</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Fitness #Workout</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 18:20:00</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#Travel #Adventure</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2023-01-15 19:55:00</td>\n",
       "      <td>ChefCook</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Cooking #Food</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0           0   \n",
       "1             1           1   \n",
       "2             2           2   \n",
       "3             3           3   \n",
       "4             4           4   \n",
       "\n",
       "                                                Text    Sentiment  \\\n",
       "0   Enjoying a beautiful day at the park!        ...   Positive     \n",
       "1   Traffic was terrible this morning.           ...   Negative     \n",
       "2   Just finished an amazing workout! ðª       ...   Positive     \n",
       "3   Excited about the upcoming weekend getaway!  ...   Positive     \n",
       "4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
       "\n",
       "             Timestamp            User     Platform  \\\n",
       "0  2023-01-15 12:30:00   User123          Twitter     \n",
       "1  2023-01-15 08:45:00   CommuterX        Twitter     \n",
       "2  2023-01-15 15:45:00   FitnessFan      Instagram    \n",
       "3  2023-01-15 18:20:00   AdventureX       Facebook    \n",
       "4  2023-01-15 19:55:00   ChefCook        Instagram    \n",
       "\n",
       "                                     Hashtags  Retweets  Likes       Country  \\\n",
       "0   #Nature #Park                                  15.0   30.0     USA         \n",
       "1   #Traffic #Morning                               5.0   10.0     Canada      \n",
       "2   #Fitness #Workout                              20.0   40.0   USA           \n",
       "3   #Travel #Adventure                              8.0   15.0     UK          \n",
       "4   #Cooking #Food                                 12.0   25.0    Australia    \n",
       "\n",
       "   Year  Month  Day  Hour  \n",
       "0  2023      1   15    12  \n",
       "1  2023      1   15     8  \n",
       "2  2023      1   15    15  \n",
       "3  2023      1   15    18  \n",
       "4  2023      1   15    19  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa293959",
   "metadata": {
    "id": "aa293959"
   },
   "outputs": [],
   "source": [
    "df = df[[\"Text\",\"Sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df4ca205",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "df4ca205",
    "outputId": "35f7c91b-1985-4658-9b61-85ce71508096"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic was terrible this morning.           ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished an amazing workout! ðª       ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text    Sentiment\n",
       "0   Enjoying a beautiful day at the park!        ...   Positive  \n",
       "1   Traffic was terrible this morning.           ...   Negative  \n",
       "2   Just finished an amazing workout! ðª       ...   Positive  \n",
       "3   Excited about the upcoming weekend getaway!  ...   Positive  \n",
       "4   Trying out a new recipe for dinner tonight.  ...   Neutral   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ab8055c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ab8055c",
    "outputId": "d9590d57-c06c-4bca-8ef1-38f3afb945f7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 732 entries, 0 to 731\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Text       732 non-null    object\n",
      " 1   Sentiment  732 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 11.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a5514fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a5514fa",
    "outputId": "4e191eae-8b7e-4bc8-da69-6b383a4fa1d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aed9502",
   "metadata": {
    "id": "7aed9502"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aleko9J1dOAj",
   "metadata": {
    "id": "aleko9J1dOAj"
   },
   "outputs": [],
   "source": [
    "word_tokens = [word_tokenize(i) for i in df[\"Text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5eda747",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5eda747",
    "outputId": "acf2636e-b28b-4121-d806-8d88db6473e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Enjoying', 'a', 'beautiful', 'day', 'at', 'the', 'park', '!'],\n",
       " ['Traffic', 'was', 'terrible', 'this', 'morning', '.'],\n",
       " ['Just', 'finished', 'an', 'amazing', 'workout', '!', 'ð\\x9f\\x92ª'],\n",
       " ['Excited', 'about', 'the', 'upcoming', 'weekend', 'getaway', '!'],\n",
       " ['Trying', 'out', 'a', 'new', 'recipe', 'for', 'dinner', 'tonight', '.']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a43d90dc",
   "metadata": {
    "id": "a43d90dc"
   },
   "outputs": [],
   "source": [
    "removal = RegexpTokenizer(r\"\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdfb72c7",
   "metadata": {
    "id": "fdfb72c7"
   },
   "outputs": [],
   "source": [
    "newsentiments = [removal.tokenize(i) for i in df[\"Text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e45e93a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e45e93a",
    "outputId": "d76df4ed-7dd5-4cff-854f-50307b4fad73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Enjoying', 'a', 'beautiful', 'day', 'at', 'the', 'park'],\n",
       " ['Traffic', 'was', 'terrible', 'this', 'morning'],\n",
       " ['Just', 'finished', 'an', 'amazing', 'workout', 'ð', 'ª'],\n",
       " ['Excited', 'about', 'the', 'upcoming', 'weekend', 'getaway'],\n",
       " ['Trying', 'out', 'a', 'new', 'recipe', 'for', 'dinner', 'tonight']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsentiments[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6fc6428",
   "metadata": {
    "id": "f6fc6428"
   },
   "outputs": [],
   "source": [
    "newString = [\" \".join(i) for i in newsentiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62282189",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62282189",
    "outputId": "cd02b112-d82d-49e5-8eb0-f9b1bcd97d4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Enjoying a beautiful day at the park',\n",
       " 'Traffic was terrible this morning',\n",
       " 'Just finished an amazing workout ð ª',\n",
       " 'Excited about the upcoming weekend getaway',\n",
       " 'Trying out a new recipe for dinner tonight']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newString[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89f0846b",
   "metadata": {
    "id": "89f0846b"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "218a0173",
   "metadata": {
    "id": "218a0173"
   },
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff8afd75",
   "metadata": {
    "id": "ff8afd75"
   },
   "outputs": [],
   "source": [
    "newStrTokens = [word_tokenize(i) for i in newString]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8672d7b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8672d7b7",
    "outputId": "6bada8f7-a23b-45e1-b5a8-a9539dca5700"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Enjoying', 'a', 'beautiful', 'day', 'at', 'the', 'park'],\n",
       " ['Traffic', 'was', 'terrible', 'this', 'morning'],\n",
       " ['Just', 'finished', 'an', 'amazing', 'workout', 'ð', 'ª'],\n",
       " ['Excited', 'about', 'the', 'upcoming', 'weekend', 'getaway'],\n",
       " ['Trying', 'out', 'a', 'new', 'recipe', 'for', 'dinner', 'tonight']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newStrTokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a95bafe6",
   "metadata": {
    "id": "a95bafe6"
   },
   "outputs": [],
   "source": [
    "updatedStrings = [[word for word in i if not word in stopWords] for i in newStrTokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e748f1ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e748f1ac",
    "outputId": "a9d0d76b-4f0d-4fc4-825f-93a4118d42aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Enjoying', 'beautiful', 'day', 'park'],\n",
       " ['Traffic', 'terrible', 'morning'],\n",
       " ['Just', 'finished', 'amazing', 'workout', 'ð', 'ª'],\n",
       " ['Excited', 'upcoming', 'weekend', 'getaway'],\n",
       " ['Trying', 'new', 'recipe', 'dinner', 'tonight']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updatedStrings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a5b1bcd",
   "metadata": {
    "id": "3a5b1bcd"
   },
   "outputs": [],
   "source": [
    "dummy = [\" \".join(i) for i in updatedStrings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "253a116a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "253a116a",
    "outputId": "c7f3c77e-09a0-4cab-e6da-2d421a41d857"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Enjoying beautiful day park',\n",
       " 'Traffic terrible morning',\n",
       " 'Just finished amazing workout ð ª',\n",
       " 'Excited upcoming weekend getaway',\n",
       " 'Trying new recipe dinner tonight']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "300d14d5",
   "metadata": {
    "id": "300d14d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahil\\AppData\\Local\\Temp\\ipykernel_17448\\2158252250.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Text\"] = dummy\n"
     ]
    }
   ],
   "source": [
    "df[\"Text\"] = dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0f92e70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "b0f92e70",
    "outputId": "5101481e-2eac-456b-c0b6-8c8ffa45fd50"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying beautiful day park</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic terrible morning</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished amazing workout ð ª</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited upcoming weekend getaway</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying new recipe dinner tonight</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Text    Sentiment\n",
       "0        Enjoying beautiful day park   Positive  \n",
       "1           Traffic terrible morning   Negative  \n",
       "2  Just finished amazing workout ð ª   Positive  \n",
       "3   Excited upcoming weekend getaway   Positive  \n",
       "4   Trying new recipe dinner tonight   Neutral   "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04939d67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04939d67",
    "outputId": "eb06c1da-7c77-489b-a1b2-b33a0fc78900"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Positive           44\n",
       " Joy                42\n",
       " Excitement         32\n",
       " Neutral            14\n",
       " Contentment        14\n",
       "                    ..\n",
       " Adrenaline          1\n",
       " Harmony             1\n",
       " ArtisticBurst       1\n",
       " Radiance            1\n",
       " Elegance            1\n",
       "Name: Sentiment, Length: 279, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee2970e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee2970e4",
    "outputId": "4b44154c-4cd5-409c-aa3f-466d68110cf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "040a8005",
   "metadata": {
    "id": "040a8005"
   },
   "outputs": [],
   "source": [
    "sentimentList = df[\"Sentiment\"].value_counts().head().index.tolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6pEJHY-YeDKD",
   "metadata": {
    "id": "6pEJHY-YeDKD"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "RYc7-ToFeMoV",
   "metadata": {
    "id": "RYc7-ToFeMoV"
   },
   "outputs": [],
   "source": [
    "tk = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "_rtjCK-keRxu",
   "metadata": {
    "id": "_rtjCK-keRxu"
   },
   "outputs": [],
   "source": [
    "tk.fit_on_texts(df[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "hvnRq6SjeUqP",
   "metadata": {
    "id": "hvnRq6SjeUqP"
   },
   "outputs": [],
   "source": [
    "tokens = tk.texts_to_sequences(df[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eH3gTny8ecW6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eH3gTny8ecW6",
    "outputId": "e034d628-6084-45d3-9599-489f822008a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[162, 307, 6, 428],\n",
       " [1074, 1075, 308],\n",
       " [309, 643, 1076, 223, 84, 429],\n",
       " [644, 72, 85, 645],\n",
       " [127, 1, 310, 430, 431]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "WhnAYAnReda8",
   "metadata": {
    "id": "WhnAYAnReda8"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tk.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "wN5QePhhenPE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wN5QePhhenPE",
    "outputId": "9ab9cfea-87b0-4a63-8a3c-7cea6283fc58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2471"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "tlxsOryjeloW",
   "metadata": {
    "id": "tlxsOryjeloW"
   },
   "outputs": [],
   "source": [
    "seq = tk.texts_to_matrix(df[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "S4oWO3M8elm7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S4oWO3M8elm7",
    "outputId": "8f410dc0-3905-4779-aec6-c3f521824069"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "Pp3lj3wQelY0",
   "metadata": {
    "id": "Pp3lj3wQelY0"
   },
   "outputs": [],
   "source": [
    "max_length = max([len(i) for i in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "xdP4qvVNemtM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdP4qvVNemtM",
    "outputId": "7e255ada-b10c-4971-e6de-de3fa153e135"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2471"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0qJRMREPe7rL",
   "metadata": {
    "id": "0qJRMREPe7rL"
   },
   "outputs": [],
   "source": [
    "pad_seq = pad_sequences(seq, maxlen=max_length, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "sX3Kh7cje7nT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sX3Kh7cje7nT",
    "outputId": "e2ee37c4-0202-49a3-97ee-b017a3ce81ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "A5Hm7SJIe7lS",
   "metadata": {
    "id": "A5Hm7SJIe7lS"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "jtTMQ82Me7jC",
   "metadata": {
    "id": "jtTMQ82Me7jC"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "vh-Cshi9e7f9",
   "metadata": {
    "id": "vh-Cshi9e7f9"
   },
   "outputs": [],
   "source": [
    "lbl = le.fit_transform(df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "h03aiJgPe7b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h03aiJgPe7b3",
    "outputId": "4b895ceb-ef63-4190-8c02-afaf6d14c41b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([214, 195, 214, 214, 197, 214, 214, 214, 195, 197, 214, 195, 214,\n",
       "       214, 197, 214, 214, 214, 197, 195, 214, 214, 214, 214, 214, 214,\n",
       "       214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214,\n",
       "       214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214, 214,\n",
       "        15, 115, 240,  83, 137, 173, 184,  13, 100,   4,   9,  26,  80,\n",
       "       257,   0,   6,  16,  31,  38,  52, 111, 176, 218, 248,  15, 115,\n",
       "       240,  83, 137, 173, 184,  13, 100,   4,   9,  26,  80, 257,   0,\n",
       "         6,  16,  31,  38,  52, 111, 176, 218, 248,   0, 111,  31,  38,\n",
       "        51, 110, 176, 218, 247,  89, 109,  57, 245, 132, 151,  95,  47,\n",
       "       261,  22, 102, 124, 235,  89, 109,  57, 245, 132, 151,  95,  47,\n",
       "       261,  22, 102, 124, 235,  89,  89, 109,  57, 245, 132, 151,  95,\n",
       "        46, 261,  22, 102, 125, 234,  89, 109,  57, 245, 132, 151,  95,\n",
       "        47, 261,  22, 102, 125, 234,  88,  75, 135, 180, 170, 231, 123,\n",
       "        36,  19, 165, 149, 105, 227,  84,  74, 135, 178, 170, 231, 122,\n",
       "        36,  18, 164, 148, 105, 227,  84,  75, 135, 178, 169, 231, 123,\n",
       "        36,  68, 158,  53, 203, 187, 201,  12,   1,  78, 246,  68, 158,\n",
       "        53, 203, 187, 201,  12,   1,  78, 246,  68, 158,  53, 203, 187,\n",
       "       201,  12,   1,  78, 246, 158,  53, 203, 187, 201,  12,   1,  78,\n",
       "       246,  68, 158,  53, 203, 187, 201,  12,   1,  78, 246,  68, 202,\n",
       "       278,  56, 152, 220, 127,  94,  48, 211, 118, 163, 152,  50, 243,\n",
       "        64,  11, 127, 278,  48, 220, 152, 211, 163,  56,  94, 118, 127,\n",
       "        50, 152, 211, 163, 152,  48, 220, 152, 211, 163,  56,  94, 118,\n",
       "       127,  50, 152, 211, 163, 152,  48, 220, 152, 211,  72,  32, 178,\n",
       "       277, 116,  21, 208, 168,  79, 121, 103,  85, 121, 178, 116,  32,\n",
       "       208, 168,  79, 121, 103,  85,  72,  32, 178, 277, 116,  21, 208,\n",
       "       168,  79, 121, 103,  85, 121, 178,  27,  77, 200, 264,  39, 209,\n",
       "       110, 130,  33,  67,   5, 207, 162, 193, 132,  95,  14,  55, 175,\n",
       "       112, 242,  34, 245,  17, 224, 199,  20,  49,  57, 102, 258,   2,\n",
       "       276, 206, 219, 138,  89,  66,  97, 166, 212, 190,  86,  90, 270,\n",
       "       210, 263, 141,  61, 221, 274, 228, 160,  58, 129,   8, 107,  25,\n",
       "        97, 188, 117, 159, 119,  70, 270, 224,   7, 142,  23, 222, 275,\n",
       "       228, 161,  58, 129,  63, 108,  25,  65, 111,  56, 233, 156, 198,\n",
       "       253, 131, 185, 244, 146, 179, 134,  73,  30, 255,  93, 226, 134,\n",
       "       167,  81, 182,  73, 186,  32, 113, 252,  69,  76, 237,  71, 225,\n",
       "       133, 178,  32,  71, 145, 133,  29, 232, 167, 225,  72, 251,  71,\n",
       "       133,  29, 145,  72, 181, 144, 198, 133,  29,  72,  71, 225, 181,\n",
       "        29, 250, 172, 136,  56, 101, 128,   2, 215, 172, 177, 120, 183,\n",
       "       172, 110, 256,  64, 128, 160, 254, 136, 262, 223,  96, 110, 172,\n",
       "       114,  24, 243,  10, 236,  24, 110,  40, 243, 273,  24,   2, 114,\n",
       "         8, 267, 126,  92,  98,  96, 198, 243, 172,  41,  44,  87, 150,\n",
       "       101,  60,  92,  45, 217, 153,  54, 154, 106, 171, 110, 198,  99,\n",
       "       217, 266, 128, 160,  55, 259, 241, 172, 160, 110,   3,  40, 268,\n",
       "        24, 262,  77, 147,  81, 122, 223, 204, 260, 216, 230, 191,  43,\n",
       "        72, 267,   8, 249,  60,  37, 140, 174, 104, 155, 269, 189,  62,\n",
       "       272, 265, 194,  42,  59, 238, 205, 271, 110,  35, 172, 122, 256,\n",
       "       157, 241,  82, 256, 172, 110, 172, 110, 122, 172, 217, 110, 172,\n",
       "       172, 110,  64,  64,  56, 128,  64,  56,  64, 172, 172,  56, 172,\n",
       "       172,  56,  56,  56, 172, 128,  64,  56, 172, 172, 128, 110, 172,\n",
       "       172,  56, 172, 172, 172,  56, 172, 110, 128, 110, 172, 172, 172,\n",
       "       128,  64, 172, 128, 110, 229, 110, 110, 172, 110, 213,  91, 110,\n",
       "       172, 172, 172, 110, 110, 172, 110, 192, 110,  91,  91,  91, 172,\n",
       "       110, 192, 110, 172,  91,  91, 172, 110, 172, 110, 172,  91, 110,\n",
       "       172, 110, 172, 110, 172,  91, 110, 239, 143,  28, 239, 143,  28,\n",
       "       239, 239, 143,  28, 239, 143,  28, 239, 239, 143,  28, 239, 143,\n",
       "        28, 239, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
       "       196, 196, 196, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,\n",
       "       139, 139, 139, 139])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "zQ6WbS3xe7Zl",
   "metadata": {
    "id": "zQ6WbS3xe7Zl"
   },
   "outputs": [],
   "source": [
    "cls = le.classes_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "SwwLPZ3ne7WR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SwwLPZ3ne7WR",
    "outputId": "c45b0ad3-5d1d-46b2-d6e7-6962813ed1e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Acceptance   ',\n",
       " ' Acceptance      ',\n",
       " ' Accomplishment ',\n",
       " ' Admiration ',\n",
       " ' Admiration   ',\n",
       " ' Admiration    ',\n",
       " ' Adoration    ',\n",
       " ' Adrenaline     ',\n",
       " ' Adventure ',\n",
       " ' Affection    ',\n",
       " ' Amazement ',\n",
       " ' Ambivalence ',\n",
       " ' Ambivalence     ',\n",
       " ' Amusement    ',\n",
       " ' Amusement     ',\n",
       " ' Anger        ',\n",
       " ' Anticipation ',\n",
       " ' Anticipation  ',\n",
       " ' Anxiety   ',\n",
       " ' Anxiety         ',\n",
       " ' Appreciation  ',\n",
       " ' Apprehensive ',\n",
       " ' Arousal       ',\n",
       " ' ArtisticBurst ',\n",
       " ' Awe ',\n",
       " ' Awe    ',\n",
       " ' Awe          ',\n",
       " ' Awe           ',\n",
       " ' Bad ',\n",
       " ' Betrayal ',\n",
       " ' Betrayal      ',\n",
       " ' Bitter       ',\n",
       " ' Bitterness ',\n",
       " ' Bittersweet ',\n",
       " ' Blessed       ',\n",
       " ' Boredom ',\n",
       " ' Boredom         ',\n",
       " ' Breakthrough ',\n",
       " ' Calmness     ',\n",
       " ' Calmness      ',\n",
       " ' Captivation ',\n",
       " ' Celebration ',\n",
       " ' Celestial Wonder ',\n",
       " ' Challenge ',\n",
       " ' Charm ',\n",
       " ' Colorful ',\n",
       " ' Compassion',\n",
       " ' Compassion    ',\n",
       " ' Compassionate ',\n",
       " ' Confidence    ',\n",
       " ' Confident ',\n",
       " ' Confusion ',\n",
       " ' Confusion    ',\n",
       " ' Confusion       ',\n",
       " ' Connection ',\n",
       " ' Contemplation ',\n",
       " ' Contentment ',\n",
       " ' Contentment   ',\n",
       " ' Coziness     ',\n",
       " ' Creative Inspiration ',\n",
       " ' Creativity ',\n",
       " ' Creativity   ',\n",
       " ' Culinary Adventure ',\n",
       " ' CulinaryOdyssey ',\n",
       " ' Curiosity ',\n",
       " ' Curiosity  ',\n",
       " ' Curiosity   ',\n",
       " ' Curiosity     ',\n",
       " ' Curiosity       ',\n",
       " ' Darkness     ',\n",
       " ' Dazzle        ',\n",
       " ' Desolation ',\n",
       " ' Despair ',\n",
       " ' Despair   ',\n",
       " ' Despair      ',\n",
       " ' Despair         ',\n",
       " ' Desperation ',\n",
       " ' Determination ',\n",
       " ' Determination   ',\n",
       " ' Devastated ',\n",
       " ' Disappointed ',\n",
       " ' Disappointment ',\n",
       " ' Disgust ',\n",
       " ' Disgust      ',\n",
       " ' Disgust         ',\n",
       " ' Dismissive ',\n",
       " ' DreamChaser   ',\n",
       " ' Ecstasy ',\n",
       " ' Elation   ',\n",
       " ' Elation       ',\n",
       " ' Elegance ',\n",
       " ' Embarrassed ',\n",
       " ' Emotion ',\n",
       " ' EmotionalStorm ',\n",
       " ' Empathetic ',\n",
       " ' Empowerment   ',\n",
       " ' Enchantment ',\n",
       " ' Enchantment   ',\n",
       " ' Energy ',\n",
       " ' Engagement ',\n",
       " ' Enjoyment    ',\n",
       " ' Enthusiasm ',\n",
       " ' Enthusiasm    ',\n",
       " ' Envious ',\n",
       " ' Envisioning History ',\n",
       " ' Envy            ',\n",
       " ' Euphoria ',\n",
       " ' Euphoria   ',\n",
       " ' Euphoria     ',\n",
       " ' Euphoria      ',\n",
       " ' Excitement ',\n",
       " ' Excitement   ',\n",
       " ' Excitement    ',\n",
       " ' Exhaustion ',\n",
       " ' Exploration ',\n",
       " ' Fear         ',\n",
       " ' Fearful ',\n",
       " ' FestiveJoy    ',\n",
       " ' Free-spirited ',\n",
       " ' Freedom       ',\n",
       " ' Friendship ',\n",
       " ' Frustrated ',\n",
       " ' Frustration ',\n",
       " ' Frustration     ',\n",
       " ' Fulfillment  ',\n",
       " ' Fulfillment   ',\n",
       " ' Grandeur ',\n",
       " ' Grateful ',\n",
       " ' Gratitude ',\n",
       " ' Gratitude  ',\n",
       " ' Gratitude   ',\n",
       " ' Gratitude    ',\n",
       " ' Gratitude     ',\n",
       " ' Grief ',\n",
       " ' Grief      ',\n",
       " ' Grief           ',\n",
       " ' Happiness ',\n",
       " ' Happiness    ',\n",
       " ' Happiness     ',\n",
       " ' Happy ',\n",
       " ' Harmony ',\n",
       " ' Harmony    ',\n",
       " ' Harmony       ',\n",
       " ' Hate ',\n",
       " ' Heartache ',\n",
       " ' Heartbreak ',\n",
       " ' Heartbreak    ',\n",
       " ' Heartwarming ',\n",
       " ' Helplessness ',\n",
       " ' Helplessness    ',\n",
       " ' Hope ',\n",
       " ' Hope          ',\n",
       " ' Hopeful ',\n",
       " ' Hypnotic ',\n",
       " ' Iconic ',\n",
       " ' Imagination ',\n",
       " ' Immersion ',\n",
       " ' Indifference ',\n",
       " ' Indifference    ',\n",
       " ' InnerJourney  ',\n",
       " ' Inspiration ',\n",
       " ' Inspiration  ',\n",
       " ' Inspiration   ',\n",
       " ' Inspired ',\n",
       " ' Intimidation ',\n",
       " ' Intimidation    ',\n",
       " ' Intrigue      ',\n",
       " ' Isolation ',\n",
       " ' Jealous ',\n",
       " ' Jealousy    ',\n",
       " ' Jealousy        ',\n",
       " ' Journey ',\n",
       " ' Joy ',\n",
       " ' Joy          ',\n",
       " ' Joy in Baking ',\n",
       " ' JoyfulReunion ',\n",
       " ' Kind         ',\n",
       " ' Kindness ',\n",
       " ' Loneliness ',\n",
       " ' Loneliness    ',\n",
       " ' Loneliness      ',\n",
       " ' Loss ',\n",
       " ' LostLove ',\n",
       " ' Love ',\n",
       " ' Love         ',\n",
       " ' Marvel       ',\n",
       " ' Melancholy ',\n",
       " ' Melancholy      ',\n",
       " ' Melodic       ',\n",
       " ' Mesmerizing ',\n",
       " ' Mindfulness   ',\n",
       " ' Miscalculation ',\n",
       " ' Mischievous ',\n",
       " ' Motivation    ',\n",
       " \" Nature's Beauty \",\n",
       " ' Negative  ',\n",
       " ' Neutral ',\n",
       " ' Neutral   ',\n",
       " ' Nostalgia ',\n",
       " ' Nostalgia     ',\n",
       " ' Nostalgia      ',\n",
       " ' Nostalgia       ',\n",
       " ' Numbness ',\n",
       " ' Numbness        ',\n",
       " ' Obstacle ',\n",
       " \" Ocean's Freedom \",\n",
       " ' Optimism      ',\n",
       " ' Overjoyed     ',\n",
       " ' Overwhelmed ',\n",
       " ' Overwhelmed   ',\n",
       " ' Pensive ',\n",
       " ' Playful ',\n",
       " ' PlayfulJoy    ',\n",
       " ' Positive ',\n",
       " ' Positive  ',\n",
       " ' Positivity ',\n",
       " ' Pressure ',\n",
       " ' Pride ',\n",
       " ' Pride        ',\n",
       " ' Pride         ',\n",
       " ' Proud ',\n",
       " ' Radiance    ',\n",
       " ' Radiance      ',\n",
       " ' Reflection ',\n",
       " ' Reflection    ',\n",
       " ' Regret ',\n",
       " ' Regret        ',\n",
       " ' Regret         ',\n",
       " ' Rejuvenation ',\n",
       " ' Relief ',\n",
       " ' Renewed Effort ',\n",
       " ' Resentment      ',\n",
       " ' Resilience ',\n",
       " ' Resilience   ',\n",
       " ' Reverence ',\n",
       " ' Reverence     ',\n",
       " ' Romance ',\n",
       " ' Ruins      ',\n",
       " ' Runway Creativity ',\n",
       " ' Sad ',\n",
       " ' Sadness      ',\n",
       " ' Satisfaction ',\n",
       " ' Satisfaction  ',\n",
       " ' Serenity ',\n",
       " ' Serenity   ',\n",
       " ' Serenity      ',\n",
       " ' Serenity        ',\n",
       " ' Shame ',\n",
       " ' Shame        ',\n",
       " ' Solace ',\n",
       " ' Solitude ',\n",
       " ' Sorrow ',\n",
       " ' Sorrow      ',\n",
       " ' Spark        ',\n",
       " ' Success ',\n",
       " ' Suffering ',\n",
       " ' Surprise ',\n",
       " ' Surprise     ',\n",
       " ' Surprise      ',\n",
       " ' Suspense ',\n",
       " ' Sympathy ',\n",
       " ' Tenderness    ',\n",
       " ' Thrill ',\n",
       " ' Thrill      ',\n",
       " ' Thrill        ',\n",
       " ' Thrilling Journey ',\n",
       " ' Touched ',\n",
       " ' Tranquility ',\n",
       " ' Triumph ',\n",
       " ' Vibrancy ',\n",
       " ' Whimsy        ',\n",
       " ' Whispers of the Past ',\n",
       " ' Winter Magic ',\n",
       " ' Wonder ',\n",
       " ' Wonder     ',\n",
       " ' Wonder       ',\n",
       " ' Wonderment    ',\n",
       " ' Yearning ',\n",
       " ' Zest ']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fOqjC3IQe7Ui",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fOqjC3IQe7Ui",
    "outputId": "0889aaa7-cc0d-444d-fee7-c32a76521ebb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying beautiful day park</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic terrible morning</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished amazing workout ð ª</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited upcoming weekend getaway</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying new recipe dinner tonight</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Text    Sentiment\n",
       "0        Enjoying beautiful day park   Positive  \n",
       "1           Traffic terrible morning   Negative  \n",
       "2  Just finished amazing workout ð ª   Positive  \n",
       "3   Excited upcoming weekend getaway   Positive  \n",
       "4   Trying new recipe dinner tonight   Neutral   "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aJ45KLm2e7Qt",
   "metadata": {
    "id": "aJ45KLm2e7Qt"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, 64, input_length=max_length),\n",
    "    SimpleRNN(64, activation=\"relu\"),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "x3Ip1YQee7PE",
   "metadata": {
    "id": "x3Ip1YQee7PE"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "m4rakXdue7K7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4rakXdue7K7",
    "outputId": "f61b0373-a51d-40b1-b017-091522974784"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n\n  File \"C:\\Users\\sahil\\AppData\\Local\\Temp\\ipykernel_17448\\2183500492.py\", line 1, in <module>\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py\", line 5775, in sparse_categorical_crossentropy\n\nReceived a label value of 267 which is outside the valid range of [0, 10).  Label values: 164 267 110 56 87 139 195 216 191 258 128 179 235 131 178 10 39 58 38 22 221 207 172 217 28 141 64 56 254 214 28 224\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_4947]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(pad_seq, lbl, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n\n  File \"C:\\Users\\sahil\\AppData\\Local\\Temp\\ipykernel_17448\\2183500492.py\", line 1, in <module>\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"C:\\Users\\sahil\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py\", line 5775, in sparse_categorical_crossentropy\n\nReceived a label value of 267 which is outside the valid range of [0, 10).  Label values: 164 267 110 56 87 139 195 216 191 258 128 179 235 131 178 10 39 58 38 22 221 207 172 217 28 141 64 56 254 214 28 224\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_4947]"
     ]
    }
   ],
   "source": [
    "model.fit(pad_seq, lbl, epochs=30, verbose=1)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "Lw7oDibFe7Jg",
   "metadata": {
    "id": "Lw7oDibFe7Jg"
   },
   "outputs": [],
   "source": [
    "new_text = \"Trying new recipe dinner tonigh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "jG7fw2q8e7Bn",
   "metadata": {
    "id": "jG7fw2q8e7Bn"
   },
   "outputs": [],
   "source": [
    "new_tk = tk.texts_to_sequences([new_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ADIYagAWe6-_",
   "metadata": {
    "id": "ADIYagAWe6-_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[127, 1, 310, 430]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2kFAvb1Re68G",
   "metadata": {
    "id": "2kFAvb1Re68G"
   },
   "outputs": [],
   "source": [
    "new_pad_seq = pad_sequences(new_tk, maxlen=max_length, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "RD011aFue65W",
   "metadata": {
    "id": "RD011aFue65W"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127,   1, 310, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pad_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "EdlGLrqne636",
   "metadata": {
    "id": "EdlGLrqne636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(new_pad_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eyY2oUsYe6zO",
   "metadata": {
    "id": "eyY2oUsYe6zO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10264783, 0.10055485, 0.09996774, 0.0974127 , 0.09898345,\n",
       "        0.09966146, 0.10043038, 0.10009911, 0.10023338, 0.10000908]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "TfPUhgySe6xi",
   "metadata": {
    "id": "TfPUhgySe6xi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ZRDCrxhzg8OC",
   "metadata": {
    "id": "ZRDCrxhzg8OC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Admiration '"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39612c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759cea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
